{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file \n",
    "f = open('neighbor-districts-modified.json') \n",
    "  \n",
    "# returns JSON object as a dictionary \n",
    "data = json.load(f) \n",
    "\n",
    "# sorting districts alphabetically\n",
    "districts_from_json = []\n",
    "for i in data:\n",
    "    districts_from_json.append(i)\n",
    "districts_from_json = np.array(districts_from_json)\n",
    "districts_from_json.sort()\n",
    "\n",
    "# ids for districts\n",
    "ids = np.arange(101,101+len(districts_from_json))\n",
    "\n",
    "# Dictionary for storing ids of districts\n",
    "Dict = {} \n",
    "for i in range(len(ids)):\n",
    "    Dict[districts_from_json[i]]=ids[i]\n",
    "\n",
    "# storing vertex 1 and vertex 2 of each edge\n",
    "edge1 = []\n",
    "edge2 = []\n",
    "for i in range(len(districts_from_json)):\n",
    "    for j in range(len(data[districts_from_json[i]])):\n",
    "        edge1.append(Dict[districts_from_json[i]])\n",
    "        edge2.append(Dict[data[districts_from_json[i]][j]])\n",
    "\n",
    "# Creating dataframe\n",
    "edge_list = {'District 1': edge1, 'District 2': edge2}\n",
    "edge_list = pd.DataFrame(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_names_from_json = []\n",
    "district_ids_from_json = []\n",
    "for i in range(len(districts_from_json)):\n",
    "    district_names_from_json.append(districts_from_json[i].split('/')[0])\n",
    "    district_ids_from_json.append(districts_from_json[i].split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_to_complete_ids = {}\n",
    "for i in range(len(district_names_from_json)):\n",
    "    districts_to_complete_ids[district_names_from_json[i]] = district_names_from_json[i] + '/' + district_ids_from_json[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_id_week = {}\n",
    "time_id_month = {}\n",
    "time_id_overall = {}\n",
    "date = datetime.date(2020,3,15)\n",
    "day = 1\n",
    "while True:\n",
    "    time_id_week[str(date)] = int(np.ceil(day/7))\n",
    "    time_id_month[str(date)] = int(str(date).split('-')[1])-2\n",
    "    time_id_overall[str(date)] = 1\n",
    "    if date == datetime.date(2020,9,5):\n",
    "        break\n",
    "    day+=1\n",
    "    date += datetime.timedelta(days=1)\n",
    "\n",
    "date = datetime.date(2020,3,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.covid19india.org/v4/data-all.json')\n",
    "dat = json.loads(r.text)\n",
    "\n",
    "date = datetime.date(2020,3,15)\n",
    "\n",
    "Date = []\n",
    "State = []\n",
    "District = []\n",
    "Dist_state = []\n",
    "numcases = []\n",
    "weekid = []\n",
    "monthid = []\n",
    "overallid = []\n",
    "pop = []\n",
    "\n",
    "while True:\n",
    "    for state in dat[str(date)]:\n",
    "        flag_districts=0\n",
    "        for key in dat[str(date)][state]:\n",
    "            if key == 'districts':\n",
    "                flag_districts=1\n",
    "                for district in dat[str(date)][state]['districts']:\n",
    "                    flag_delta=0\n",
    "                    for key_delta in dat[str(date)][state]['districts'][district]:\n",
    "                        if key_delta == 'delta':\n",
    "                            flag_delta=1\n",
    "                            flag_confimed=0\n",
    "                            for key_confirmed in dat[str(date)][state]['districts'][district]['delta']:\n",
    "                                if key_confirmed == 'confirmed':\n",
    "                                    flag_confirmed=1\n",
    "                                    Date.append(str(date))\n",
    "                                    State.append(state)\n",
    "                                    District.append(district)\n",
    "                                    Dist_state.append(district+':'+state)\n",
    "                                    numcases.append(dat[str(date)][state]['districts'][district]['delta']['confirmed'])\n",
    "                                    weekid.append(time_id_week[str(date)])\n",
    "                                    monthid.append(time_id_month[str(date)])\n",
    "                                    overallid.append(time_id_overall[str(date)])\n",
    "                                    if 'meta' in dat[str(date)][state]['districts'][district].keys():\n",
    "                                        if 'population' in dat[str(date)][state]['districts'][district]['meta'].keys():\n",
    "                                            pop.append(dat[str(date)][state]['districts'][district]['meta']['population'])\n",
    "                                        else:\n",
    "                                            pop.append(0)\n",
    "                                    else:\n",
    "                                        pop.append(0)\n",
    "        if flag_districts == 0:\n",
    "            flag_delta=0\n",
    "            if state== 'TT':\n",
    "                continue\n",
    "            for key in dat[str(date)][state]:\n",
    "                if key == 'delta':\n",
    "                    falg_delta=1\n",
    "                    flag_confirmed = 0\n",
    "                    for key_confirmed in dat[str(date)][state]['delta']:\n",
    "                        if key_confirmed == 'confirmed':\n",
    "                            flag_confirmed = 1\n",
    "                            Date.append(str(date))\n",
    "                            State.append(state)\n",
    "                            District.append('All Districts')\n",
    "                            numcases.append(dat[str(date)][state]['delta']['confirmed'])\n",
    "                            weekid.append(time_id_week[str(date)])\n",
    "                            monthid.append(time_id_month[str(date)])\n",
    "                            overallid.append(time_id_overall[str(date)])\n",
    "                            Dist_state.append('All Districts:'+state)\n",
    "                            pop.append(0)\n",
    "        \n",
    "    if date == datetime.date(2020,9,5):\n",
    "        break\n",
    "    date += datetime.timedelta(days=1)\n",
    "\n",
    "District_wise_data = {'Date': Date,'State': State, 'District': District, 'District_state': Dist_state, 'cases': numcases, 'weekid': weekid, 'monthid': monthid, 'overallid': overallid, 'Population': pop}\n",
    "District_wise_data = pd.DataFrame(District_wise_data)\n",
    "District_wise_data.sort_values(\"Population\", axis = 0, ascending = False, kind='mergesort', inplace = True, na_position ='last')\n",
    "District_wise_data.sort_values(\"State\", axis = 0, ascending = True, kind='mergesort', inplace = True, na_position ='last')\n",
    "District_wise_data = District_wise_data.reset_index(drop=True)\n",
    "# District_wise_data.to_csv('District_wise_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "populous_district = {}\n",
    "i=0\n",
    "while i<len(District_wise_data):\n",
    "    curr = District_wise_data['State'][i]\n",
    "    populous_district[District_wise_data['State'][i]] = District_wise_data['District'][i]\n",
    "    i+=1\n",
    "    while i<len(District_wise_data) and District_wise_data['State'][i] ==curr:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.covid19india.org/v4/data-all.json')\n",
    "dat = json.loads(r.text)\n",
    "\n",
    "date = datetime.date(2020,3,15)\n",
    "\n",
    "Date = []\n",
    "State = []\n",
    "District = []\n",
    "Dist_state = []\n",
    "numcases = []\n",
    "weekid = []\n",
    "monthid = []\n",
    "overallid = []\n",
    "pop = []\n",
    "\n",
    "while True:\n",
    "    for state in dat[str(date)]:\n",
    "        flag_districts=0\n",
    "        for key in dat[str(date)][state]:\n",
    "            if key == 'districts':\n",
    "                flag_districts=1\n",
    "                for district in dat[str(date)][state]['districts']:\n",
    "                    flag_delta=0\n",
    "                    for key_delta in dat[str(date)][state]['districts'][district]:\n",
    "                        if key_delta == 'delta':\n",
    "                            flag_delta=1\n",
    "                            flag_confimed=0\n",
    "                            for key_confirmed in dat[str(date)][state]['districts'][district]['delta']:\n",
    "                                if key_confirmed == 'confirmed':\n",
    "                                    flag_confirmed=1 \n",
    "                                    Date.append(str(date))\n",
    "                                    State.append(state)\n",
    "                                    District.append(district)\n",
    "                                    Dist_state.append(district+':'+state)\n",
    "                                    numcases.append(dat[str(date)][state]['districts'][district]['delta']['confirmed'])\n",
    "                                    weekid.append(time_id_week[str(date)])\n",
    "                                    monthid.append(time_id_month[str(date)])\n",
    "                                    overallid.append(time_id_overall[str(date)])\n",
    "#                                     Dist_id.append(Dict[districts_to_complete_ids[district.lower()]])\n",
    "                                    if 'meta' in dat[str(date)][state]['districts'][district].keys():\n",
    "                                        if 'population' in dat[str(date)][state]['districts'][district]['meta'].keys():\n",
    "                                            pop.append(dat[str(date)][state]['districts'][district]['meta']['population'])\n",
    "                                        else:\n",
    "                                            pop.append(0)\n",
    "                                    else:\n",
    "                                        pop.append(0)\n",
    "        if flag_districts == 0:\n",
    "            flag_delta=0\n",
    "            if state== 'TT':\n",
    "                continue\n",
    "            for key in dat[str(date)][state]:\n",
    "                if key == 'delta':\n",
    "                    falg_delta=1\n",
    "                    flag_confirmed = 0\n",
    "                    for key_confirmed in dat[str(date)][state]['delta']:\n",
    "                        if key_confirmed == 'confirmed':\n",
    "                            flag_confirmed = 1\n",
    "                            Date.append(str(date))\n",
    "                            State.append(state)\n",
    "                            District.append(populous_district[state])\n",
    "                            numcases.append(dat[str(date)][state]['delta']['confirmed'])\n",
    "                            weekid.append(time_id_week[str(date)])\n",
    "                            monthid.append(time_id_month[str(date)])\n",
    "                            overallid.append(time_id_overall[str(date)])\n",
    "                            Dist_state.append(populous_district[state]+':'+state)\n",
    "#                             Dist_id.append(Dict[districts_to_complete_ids[populous_district[state].lower()]])\n",
    "                            pop.append(0)\n",
    "        \n",
    "    if date == datetime.date(2020,9,5):\n",
    "        break\n",
    "    date += datetime.timedelta(days=1)\n",
    "\n",
    "District_wise_data = {'Date': Date,'State': State, 'District': District, 'District_state': Dist_state, 'cases': numcases, 'weekid': weekid, 'monthid': monthid, 'overallid': overallid, 'Population': pop, 'ID': np.zeros(len(numcases))}\n",
    "District_wise_data = pd.DataFrame(District_wise_data)\n",
    "# District_wise_data.to_csv('District_wise_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(District_wise_data)):\n",
    "    if District_wise_data['District'][i].lower()=='hamirpur' and District_wise_data['State'][i] == 'HP':\n",
    "        District_wise_data['ID'][i] = Dict['hamirpur/316']\n",
    "    elif District_wise_data['District'][i].lower()=='bilaspur' and District_wise_data['State'][i] == 'CT':\n",
    "        District_wise_data['ID'][i] = Dict['bilaspur/190']\n",
    "    elif District_wise_data['District'][i].lower()=='pratapgarh' and District_wise_data['State'][i] == 'UP':\n",
    "        District_wise_data['ID'][i] = Dict['pratapgarh/546']\n",
    "    elif District_wise_data['District'][i].lower()=='balrampur' and District_wise_data['State'][i] == 'CT':\n",
    "        District_wise_data['ID'][i] = Dict['balrampur/148']\n",
    "    elif District_wise_data['District'][i].lower()=='aurangabad' and District_wise_data['State'][i] == 'BR':\n",
    "        District_wise_data['ID'][i] = Dict['aurangabad/133']\n",
    "    elif District_wise_data['District'][i].lower() in districts_to_complete_ids.keys():\n",
    "        District_wise_data['ID'][i] = Dict[districts_to_complete_ids[District_wise_data['District'][i].lower()]]\n",
    "    else:\n",
    "        District_wise_data['ID'][i] = 0\n",
    "\n",
    "indexNames = District_wise_data[District_wise_data['ID'] == 0].index\n",
    "District_wise_data.drop(indexNames , inplace=True)\n",
    "District_wise_data = District_wise_data.reset_index(drop=True)\n",
    "\n",
    "# District_wise_data.to_csv('District_wise_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# week\n",
    "week_data = {'districtid': District_wise_data['ID'], 'weekid': District_wise_data['weekid'], 'cases':District_wise_data['cases'] }\n",
    "week_data = pd.DataFrame(week_data)\n",
    "\n",
    "weeks = week_data['weekid'].max()\n",
    "for i in range(1,weeks+1):\n",
    "    Data1 = {'districtid': np.arange(101,101+len(districts_from_json)),'weekid': i*np.ones(len(districts_from_json)),'cases':np.zeros(len(districts_from_json)) }\n",
    "    Data1 = pd.DataFrame(Data1)\n",
    "    week_data = week_data.append(Data1)\n",
    "\n",
    "sorted1 = week_data.sort_values(\"districtid\", axis = 0, ascending = True, kind='mergesort', inplace = False, na_position ='last')\n",
    "sorted2 = sorted1.sort_values(\"weekid\", axis = 0, ascending = True, kind='mergesort', inplace = False, na_position ='last')\n",
    "sorted2['dropped'] = 0\n",
    "sorted2 = sorted2.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(sorted2)-1):\n",
    "    if sorted2['districtid'][i] == sorted2['districtid'][i+1]:\n",
    "        sorted2['cases'][i+1] += sorted2['cases'][i]\n",
    "        sorted2['dropped'][i] = 1\n",
    "indexNames = sorted2[ sorted2['dropped'] == 1].index\n",
    "sorted2.drop(indexNames , inplace=True)\n",
    "sorted2 = sorted2.drop(['dropped'], axis = 1)\n",
    "sorted2 = sorted2.reset_index(drop=True)\n",
    "\n",
    "sorted2.to_csv('cases-week.csv')\n",
    "# sorted2.to_csv('cases-week.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# month\n",
    "month_data = {'districtid': District_wise_data['ID'], 'monthid': District_wise_data['monthid'], 'cases':District_wise_data['cases'] }\n",
    "month_data = pd.DataFrame(month_data)\n",
    "\n",
    "months = month_data['monthid'].max()\n",
    "for i in range(1,months+1):\n",
    "    Data1 = {'districtid': np.arange(101,101+len(districts_from_json)),'monthid': i*np.ones(len(districts_from_json)),'cases':np.zeros(len(districts_from_json)) }\n",
    "    Data1 = pd.DataFrame(Data1)\n",
    "    month_data = month_data.append(Data1)\n",
    "\n",
    "sorted1 = month_data.sort_values(\"districtid\", axis = 0, ascending = True, kind='mergesort', inplace = False, na_position ='last')\n",
    "sorted2 = sorted1.sort_values(\"monthid\", axis = 0, ascending = True, kind='mergesort', inplace = False, na_position ='last')\n",
    "sorted2['dropped'] = 0\n",
    "sorted2 = sorted2.reset_index(drop=True)\n",
    "for i in range(len(sorted2)-1):\n",
    "    if sorted2['districtid'][i] == sorted2['districtid'][i+1]:\n",
    "        sorted2['cases'][i+1] += sorted2['cases'][i]\n",
    "        sorted2['dropped'][i] = 1\n",
    "indexNames = sorted2[ sorted2['dropped'] == 1].index\n",
    "sorted2.drop(indexNames , inplace=True)\n",
    "sorted2 = sorted2.drop(['dropped'], axis = 1)\n",
    "sorted2 = sorted2.reset_index(drop=True)\n",
    "sorted2.to_csv('cases-month.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# overall\n",
    "overall_data = {'districtid': District_wise_data['ID'], 'overallid': District_wise_data['overallid'], 'cases':District_wise_data['cases'] }\n",
    "overall_data = pd.DataFrame(overall_data)\n",
    "\n",
    "sorted1 = overall_data.sort_values(\"districtid\", axis = 0, ascending = True, kind='mergesort', inplace = False, na_position ='last')\n",
    "sorted2 = sorted1.sort_values(\"overallid\", axis = 0, ascending = True, kind='mergesort', inplace = False, na_position ='last')\n",
    "sorted2['dropped'] = 0\n",
    "sorted2 = sorted2.reset_index(drop=True)\n",
    "for i in range(len(sorted2)-1):\n",
    "    if sorted2['districtid'][i] == sorted2['districtid'][i+1]:\n",
    "        sorted2['cases'][i+1] += sorted2['cases'][i]\n",
    "        sorted2['dropped'][i] = 1\n",
    "indexNames = sorted2[ sorted2['dropped'] == 1].index\n",
    "sorted2.drop(indexNames , inplace=True)\n",
    "sorted2 = sorted2.drop(['dropped'], axis = 1)\n",
    "sorted2 = sorted2.reset_index(drop=True)\n",
    "sorted2.to_csv('cases-overall.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
