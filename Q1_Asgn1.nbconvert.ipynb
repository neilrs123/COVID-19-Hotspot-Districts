{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file \n",
    "f = open('neighbor-districts.json') \n",
    "  \n",
    "# returns JSON object as a dictionary \n",
    "data = json.load(f) \n",
    "\n",
    "# list of districts - sample entry: pune_district/Q1797336\n",
    "districts_from_json = []\n",
    "for i in data:\n",
    "    districts_from_json.append(i)\n",
    "districts_from_json = np.array(districts_from_json)\n",
    "\n",
    "# sorting districts alphabetically\n",
    "districts_from_json.sort()\n",
    "\n",
    "# list of district names - sample entry: pune_district\n",
    "district_names_from_json = []\n",
    "\n",
    "# list of district ids - sample entry: Q1797336\n",
    "district_ids_from_json = []\n",
    "\n",
    "for i in range(len(districts_from_json)):\n",
    "    district_names_from_json.append(districts_from_json[i].split('/')[0])\n",
    "    district_ids_from_json.append(districts_from_json[i].split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified list of district names - \n",
    "# sample modifications: pune_district -> pune, jyotiba_phule_nagar -> amroha, agar_malwa -> agar malwa\n",
    "district_names_from_json_modified = []\n",
    "\n",
    "for i in range(len(district_names_from_json)):\n",
    "# from hshengar20, names of some districts have changed: https://hello.iitk.ac.in/cs685a/#/forum/general/64\n",
    "    if district_names_from_json[i] == 'jyotiba_phule_nagar':\n",
    "        district_names_from_json_modified.append('amroha')\n",
    "    elif district_names_from_json[i] == 'sant_ravidas_nagar':\n",
    "        district_names_from_json_modified.append('bhadohi')\n",
    "    elif district_names_from_json[i] == 'bijapur_district':\n",
    "        district_names_from_json_modified.append('vijayapura')\n",
    "    elif district_names_from_json[i] == 'palghat':\n",
    "        district_names_from_json_modified.append('palakkad')\n",
    "    elif district_names_from_json[i] == 'faizabad':\n",
    "        district_names_from_json_modified.append('ayodhya')\n",
    "# discrepancies dicovered by me which need to be resolved manually\n",
    "    elif district_names_from_json[i] == 'baleshwar':\n",
    "        district_names_from_json_modified.append('balasore')\n",
    "    elif district_names_from_json[i] == 'ysr':\n",
    "        district_names_from_json_modified.append('y.s.r kadapa')\n",
    "    elif district_names_from_json[i] == 'purbi_singhbhum':\n",
    "        district_names_from_json_modified.append('east singhbhum')\n",
    "    elif district_names_from_json[i] == 'pashchimi_singhbhum':\n",
    "        district_names_from_json_modified.append('west singhbhum')\n",
    "    elif district_names_from_json[i] == 'purba_champaran':\n",
    "        district_names_from_json_modified.append('east champaran')\n",
    "    elif district_names_from_json[i] == 'pashchim_champaran':\n",
    "        district_names_from_json_modified.append('west champaran')\n",
    "    elif district_names_from_json[i] == 'tirunelveli_kattabo':\n",
    "        district_names_from_json_modified.append('tirunelveli')\n",
    "    elif district_names_from_json[i] == 'the_nilgiris_district':\n",
    "        district_names_from_json_modified.append('nilgiris')\n",
    "    elif district_names_from_json[i] == 'tirunelveli_kattabo':\n",
    "        district_names_from_json_modified.append('tirunelveli')\n",
    "    elif district_names_from_json[i] == 'hugli':\n",
    "        district_names_from_json_modified.append('hooghly')\n",
    "    elif district_names_from_json[i] == 'sri_ganganagar':\n",
    "        district_names_from_json_modified.append('ganganagar')\n",
    "    elif district_names_from_json[i] == 'the_dangs':\n",
    "        district_names_from_json_modified.append('dang')\n",
    "    elif district_names_from_json[i] == 'lakhimpur':\n",
    "        district_names_from_json_modified.append('lakhimpur kheri')\n",
    "    elif district_names_from_json[i] == 'sahibzada_ajit_singh_nagar':\n",
    "        district_names_from_json_modified.append('s.a.s. nagar')\n",
    "    elif district_names_from_json[i] == 'sri_potti_sriramulu_nellore':\n",
    "        district_names_from_json_modified.append('s.p.s. nellore')\n",
    "    elif district_names_from_json[i] == 'muktsar':\n",
    "        district_names_from_json_modified.append('sri muktsar sahib')\n",
    "    elif district_names_from_json[i] == 'dantewada':\n",
    "        district_names_from_json_modified.append('dakshin bastar dantewada')\n",
    "    elif district_names_from_json[i] == 'kochbihar':\n",
    "        district_names_from_json_modified.append('cooch behar')\n",
    "    elif district_names_from_json[i] == 'sonapur':\n",
    "        district_names_from_json_modified.append('subarnapur') \n",
    "    else:\n",
    "        district_names_from_json_modified.append(district_names_from_json[i])\n",
    "# removing \"_district\" from district names\n",
    "    if len(district_names_from_json_modified[i])>9 and district_names_from_json_modified[i][-9:] == '_district':\n",
    "        district_names_from_json_modified[i] = district_names_from_json_modified[i][:-9]\n",
    "# replacing \"_\" by \" \" in district names\n",
    "    for j in range(len(district_names_from_json_modified[i])):\n",
    "        if district_names_from_json_modified[i][j] == '_':\n",
    "            district_names_from_json_modified[i] = district_names_from_json_modified[i][:j] + ' ' + district_names_from_json_modified[i][j+1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries for mapping dates to time ids\n",
    "# eg. for 2020-3-15, time_id_week is 1, time_id_month is 1, time_id_overall is 1\n",
    "\n",
    "time_id_week = {}\n",
    "time_id_month = {}\n",
    "time_id_overall = {}\n",
    "date = datetime.date(2020,3,15)\n",
    "day = 1\n",
    "while True:\n",
    "    time_id_week[str(date)] = int(np.ceil(day/7))\n",
    "    time_id_month[str(date)] = int(str(date).split('-')[1])-2\n",
    "    time_id_overall[str(date)] = 1\n",
    "    if date == datetime.date(2020,9,5):\n",
    "        break\n",
    "    day+=1\n",
    "    date += datetime.timedelta(days=1)\n",
    "\n",
    "date = datetime.date(2020,3,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Covid Data into lists\n",
    "r = requests.get('https://api.covid19india.org/v4/data-all.json')\n",
    "dat = json.loads(r.text)\n",
    "\n",
    "date = datetime.date(2020,3,15)\n",
    "\n",
    "Date = []\n",
    "State = []\n",
    "District = []\n",
    "Dist_state = []\n",
    "numcases = []\n",
    "weekid = []\n",
    "monthid = []\n",
    "overallid = []\n",
    "\n",
    "while True:\n",
    "    for state in dat[str(date)]:\n",
    "        flag_districts=0\n",
    "        for key in dat[str(date)][state]:\n",
    "            if key == 'districts':\n",
    "                flag_districts=1\n",
    "                for district in dat[str(date)][state]['districts']:\n",
    "                    flag_delta=0\n",
    "                    for key_delta in dat[str(date)][state]['districts'][district]:\n",
    "                        if key_delta == 'delta':\n",
    "                            flag_delta=1\n",
    "                            flag_confimed=0\n",
    "                            for key_confirmed in dat[str(date)][state]['districts'][district]['delta']:\n",
    "                                if key_confirmed == 'confirmed':\n",
    "                                    flag_confirmed=1\n",
    "                                    Date.append(str(date))\n",
    "                                    State.append(state)\n",
    "                                    District.append(district)\n",
    "                                    Dist_state.append(district+':'+state)\n",
    "                                    numcases.append(dat[str(date)][state]['districts'][district]['delta']['confirmed'])\n",
    "                                    weekid.append(time_id_week[str(date)])\n",
    "                                    monthid.append(time_id_month[str(date)])\n",
    "                                    overallid.append(time_id_overall[str(date)])\n",
    "        if flag_districts == 0:\n",
    "            flag_delta=0\n",
    "            if state== 'TT':\n",
    "                continue\n",
    "            for key in dat[str(date)][state]:\n",
    "                if key == 'delta':\n",
    "                    falg_delta=1\n",
    "                    flag_confirmed = 0\n",
    "                    for key_confirmed in dat[str(date)][state]['delta']:\n",
    "                        if key_confirmed == 'confirmed':\n",
    "                            flag_confirmed = 1\n",
    "                            Date.append(str(date))\n",
    "                            State.append(state)\n",
    "                            District.append('All Districts')\n",
    "                            numcases.append(dat[str(date)][state]['delta']['confirmed'])\n",
    "                            weekid.append(time_id_week[str(date)])\n",
    "                            monthid.append(time_id_month[str(date)])\n",
    "                            overallid.append(time_id_overall[str(date)])\n",
    "                            Dist_state.append('All Districts:'+state)\n",
    "        \n",
    "    if date == datetime.date(2020,9,5):\n",
    "        break\n",
    "    date += datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editdist(str1, str2): \n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    "    # Create a table to store results of subproblems\n",
    "    dp = [[0 for x in range(n + 1)] for x in range(m + 1)] \n",
    "  \n",
    "    # Fill d[][] in bottom up manner \n",
    "    for i in range(m + 1): \n",
    "        for j in range(n + 1): \n",
    "  \n",
    "            # If first string is empty, only option is to \n",
    "            # insert all characters of second string \n",
    "            if i == 0: \n",
    "                dp[i][j] = j    # Min. operations = j \n",
    "  \n",
    "            # If second string is empty, only option is to \n",
    "            # remove all characters of second string \n",
    "            elif j == 0: \n",
    "                dp[i][j] = i    # Min. operations = i \n",
    "  \n",
    "            # If last characters are same, ignore last char \n",
    "            # and recur for remaining string \n",
    "            elif str1[i-1] == str2[j-1]: \n",
    "                dp[i][j] = dp[i-1][j-1] \n",
    "  \n",
    "            # If last character are different, consider all \n",
    "            # possibilities and find minimum \n",
    "            else: \n",
    "                dp[i][j] = 1 + min(dp[i][j-1],        # Insert \n",
    "                                   dp[i-1][j],        # Remove \n",
    "                                   dp[i-1][j-1])    # Replace \n",
    "  \n",
    "    return dp[m][n] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neilrs/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/neilrs/.local/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "District_set = set()\n",
    "\n",
    "for i in range(len(District)):\n",
    "    District_set.add(District[i].lower() +':'+ State[i])\n",
    "    \n",
    "district_names_from_data_all = []\n",
    "district_states_from_data_all = []\n",
    "for dist in District_set:\n",
    "    dis = dist.split(':')[0]\n",
    "    if dis == 'all districts' or dis == 'italians' or dis == 'unknown' or dis == 'foreign evacuees' or dis == 'airport quarantine' or dis == 'railway quarantine' or dis == 'other region' or dis == 'other state' or dis == 'others' or dis =='bsf camp' :\n",
    "        continue\n",
    "    district_names_from_data_all.append(dis)\n",
    "    district_states_from_data_all.append(dist.split(':')[1])\n",
    "\n",
    "equivalent_district = []\n",
    "equivalent_state = []\n",
    "completed = np.zeros(len(district_names_from_data_all))\n",
    "    \n",
    "website_districts = {'District_Name': district_names_from_data_all, 'State': district_states_from_data_all, 'Completed': completed}\n",
    "website_districts = pd.DataFrame(website_districts)\n",
    "website_districts.sort_values(\"District_Name\", axis = 0, ascending = True, kind='mergesort', inplace = True, na_position ='last')\n",
    "website_districts = website_districts.reset_index(drop=True)\n",
    "\n",
    "\n",
    "for i in range(len(district_names_from_json_modified)):\n",
    "    found = 0\n",
    "    for j in range(len(website_districts)):\n",
    "#         if mod_sorted(district_names_from_json_modified[i])==mod_sorted(district_names_from_data_all[j]) and completed[j]==0:\n",
    "        if district_names_from_json_modified[i]==website_districts['District_Name'][j] and website_districts['Completed'][j]==0:\n",
    "            equivalent_district.append(website_districts['District_Name'][j])\n",
    "            website_districts['Completed'][j]=1\n",
    "            found = 1\n",
    "            equivalent_state.append(website_districts['State'][j])\n",
    "            break\n",
    "    if found==0:\n",
    "        equivalent_district.append('#')\n",
    "        equivalent_state.append('#')\n",
    "\n",
    "for i in range(len(district_names_from_json_modified)):\n",
    "    if equivalent_district[i]=='#':\n",
    "        for j in range(len(website_districts)):\n",
    "            if editdist(district_names_from_json_modified[i],website_districts['District_Name'][j])<4 and website_districts['District_Name'][j][0]==district_names_from_json_modified[i][0] and website_districts['Completed'][j]==0:\n",
    "                equivalent_district[i]=website_districts['District_Name'][j]\n",
    "                website_districts['Completed'][j]=1\n",
    "                equivalent_state[i] = website_districts['State'][j]\n",
    "                break\n",
    "    \n",
    "json_districts = {'Names from Json': district_names_from_json, 'IDs': district_ids_from_json, 'Modified Names': district_names_from_json_modified, 'Equivalent from website': equivalent_district, 'state': equivalent_state}\n",
    "json_districts = pd.DataFrame(json_districts)\n",
    "\n",
    "# manual adjustment for districts with same name\n",
    "# bilaspur\n",
    "json_districts['IDs'][94], json_districts['IDs'][93] = json_districts['IDs'][93], json_districts['IDs'][94]\n",
    "# balrampur\n",
    "json_districts['IDs'][47], json_districts['IDs'][48] = json_districts['IDs'][48], json_districts['IDs'][47]\n",
    "# hamirpur\n",
    "json_districts['IDs'][230], json_districts['IDs'][231] = json_districts['IDs'][231], json_districts['IDs'][230]\n",
    "# aurangabad, pratapgarh - no issues\n",
    "\n",
    "\n",
    "new_districts = []\n",
    "for i in range(len(website_districts)):\n",
    "    if website_districts['Completed'][i]==0:\n",
    "        new_districts.append(website_districts['District_Name'][i] +'/Q' + str(randint(100000, 999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_name_equivalent = {}\n",
    "for i in range(len(districts_from_json)):\n",
    "    if equivalent_district[i] == '#':\n",
    "        district_name_equivalent[districts_from_json[i]] = equivalent_district[i]\n",
    "    else:\n",
    "        district_name_equivalent[districts_from_json[i]] = equivalent_district[i] + '/' + json_districts['IDs'][i]\n",
    "\n",
    "data_modified = {}\n",
    "for i in range(len(districts_from_json)):\n",
    "    if district_name_equivalent[districts_from_json[i]] != '#':\n",
    "        data_modified[district_name_equivalent[districts_from_json[i]]] = []\n",
    "        for j in range(len(data[districts_from_json[i]])):\n",
    "            if district_name_equivalent[data[districts_from_json[i]][j]]!='#':\n",
    "                data_modified[district_name_equivalent[districts_from_json[i]]].append(district_name_equivalent[data[districts_from_json[i]][j]])\n",
    "\n",
    "districts_to_complete_ids = {}\n",
    "for i in range(len(equivalent_district)):\n",
    "    districts_to_complete_ids[equivalent_district[i]] = equivalent_district[i] + '/' + json_districts['IDs'][i]\n",
    "\n",
    "for i in range(len(new_districts)):\n",
    "    districts_to_complete_ids[new_districts[i].split('/')[0]] = new_districts[i]\n",
    "\n",
    "for dis in new_districts:\n",
    "    data_modified[dis] = []\n",
    "    \n",
    "# Manual Changes to be done \n",
    "\n",
    "# gaurela pendra marwahi: mungeli, bilaspur, korba, koriya, anuppur | part of bilaspur: add gaurela pendra marwahi, delete anuppur, koriya\n",
    "# ranipet: vellore, thiruvallur, kanchipuram, tiruvannamalai | part of kanchipuram_district\n",
    "# chngalpattu: chennai, kanchipuram, tiruvannamalai, viluppuram  | part of kanchipuram_district\n",
    "# Changes in kanchipuram: remove viluppuram, vellore, add ranipet, changalpattu\n",
    "# hnahthial: lunglei, serchhip | part of lunglei (no change)\n",
    "# khawzawl: champhai, saitual, serchhip | part of champhai\n",
    "# saitual: aizawl, champhai, khawzawl, serchhip | part of champhai\n",
    "# changes in champhai: remove aizwal, add saitual, khawzawl\n",
    "# yanam: east godavari | Part of pondicherry (no change)\n",
    "# tenkasi: tirunelvelli , virudhunagar, kollam, thiruvananthapuram, thoothukudi | part of tirunelvelli: add tenkasi, delete idukki, virudhunagar, kollam, thiruvananthapuram \n",
    "# tirupathur: krishnagiri, tiruvannamalai, vellore, chittoor | part of vellore: add ranipet, tirupathur, remove krishnagiri, kanchipuram\n",
    "\n",
    "# mumbai: thane | combine mumbai city and mumbai suburban\n",
    "# delhi: ghaziabad, gautam_buddha_nagar, gurugram, sonipat, baghpat, jhajjar, faridabad | combine 10 districts in delhi, shahdara\n",
    "\n",
    "for key in data_modified:\n",
    "    if key.split('/')[0]== 'gaurela pendra marwahi':\n",
    "        data_modified[key].append(districts_to_complete_ids['mungeli'])\n",
    "        data_modified[key].append('bilaspur/Q100157')\n",
    "        data_modified[key].append(districts_to_complete_ids['korba'])\n",
    "        data_modified[key].append(districts_to_complete_ids['koriya'])\n",
    "        data_modified[key].append(districts_to_complete_ids['anuppur'])\n",
    "        data_modified[districts_to_complete_ids['mungeli']].append(key)\n",
    "        data_modified['bilaspur/Q100157'].append(key)\n",
    "        data_modified[districts_to_complete_ids['korba']].append(key)\n",
    "        data_modified[districts_to_complete_ids['koriya']].append(key)\n",
    "        data_modified[districts_to_complete_ids['anuppur']].append(key)\n",
    "    elif key.split('/')[0]== 'ranipet':\n",
    "        data_modified[key].append(districts_to_complete_ids['vellore'])\n",
    "        data_modified[key].append(districts_to_complete_ids['thiruvallur'])\n",
    "        data_modified[key].append(districts_to_complete_ids['kancheepuram'])\n",
    "        data_modified[key].append(districts_to_complete_ids['tiruvannamalai'])\n",
    "        data_modified[districts_to_complete_ids['vellore']].append(key)\n",
    "        data_modified[districts_to_complete_ids['thiruvallur']].append(key)\n",
    "        data_modified[districts_to_complete_ids['kancheepuram']].append(key)\n",
    "        data_modified[districts_to_complete_ids['tiruvannamalai']].append(key)\n",
    "    elif key.split('/')[0]== 'tirupathur':\n",
    "        data_modified[key].append(districts_to_complete_ids['krishnagiri'])\n",
    "        data_modified[key].append(districts_to_complete_ids['tiruvannamalai'])\n",
    "        data_modified[key].append(districts_to_complete_ids['vellore'])\n",
    "        data_modified[key].append(districts_to_complete_ids['chittoor'])\n",
    "        data_modified[districts_to_complete_ids['vellore']].append(key)\n",
    "        data_modified[districts_to_complete_ids['krishnagiri']].append(key)\n",
    "        data_modified[districts_to_complete_ids['chittoor']].append(key)\n",
    "        data_modified[districts_to_complete_ids['tiruvannamalai']].append(key)\n",
    "    elif key.split('/')[0]== 'chngalpattu':\n",
    "        data_modified[key].append(districts_to_complete_ids['chennai'])\n",
    "        data_modified[key].append(districts_to_complete_ids['kancheepuram'])\n",
    "        data_modified[key].append(districts_to_complete_ids['tiruvannamalai'])\n",
    "        data_modified[key].append(districts_to_complete_ids['viluppuram'])\n",
    "        data_modified[districts_to_complete_ids['chennai']].append(key)\n",
    "        data_modified[districts_to_complete_ids['kancheepuram']].append(key)\n",
    "        data_modified[districts_to_complete_ids['tiruvannamalai']].append(key)\n",
    "        data_modified[districts_to_complete_ids['viluppuram']].append(key)\n",
    "    elif key.split('/')[0]== 'kancheepuram':\n",
    "        for key2 in data_modified[key]:\n",
    "            if key2.split('/')[0] == 'viluppuram' or key2.split('/')[0] == 'vellore':\n",
    "                data_modified[key].remove(key2)\n",
    "                data_modified[key2].remove(key)\n",
    "    elif key.split('/')[0]== 'vellore':\n",
    "        for key2 in data_modified[key]:\n",
    "            if key2.split('/')[0] == 'krishnagiri':\n",
    "                data_modified[key].remove(key2)\n",
    "                data_modified[key2].remove(key)\n",
    "    elif key.split('/')[0]== 'hnahthial':\n",
    "        data_modified[key].append(districts_to_complete_ids['lunglei'])\n",
    "        data_modified[key].append(districts_to_complete_ids['serchhip'])\n",
    "        data_modified[districts_to_complete_ids['serchhip']].append(key)\n",
    "        data_modified[districts_to_complete_ids['lunglei']].append(key)\n",
    "    elif key.split('/')[0]== 'khawzawl':\n",
    "        data_modified[key].append(districts_to_complete_ids['champhai'])\n",
    "        data_modified[key].append(districts_to_complete_ids['saitual'])\n",
    "        data_modified[key].append(districts_to_complete_ids['serchhip'])\n",
    "        data_modified[districts_to_complete_ids['champhai']].append(key)\n",
    "        data_modified[districts_to_complete_ids['saitual']].append(key)\n",
    "        data_modified[districts_to_complete_ids['serchhip']].append(key)\n",
    "    elif key.split('/')[0]== 'saitual':\n",
    "        data_modified[key].append(districts_to_complete_ids['aizawl'])\n",
    "        data_modified[key].append(districts_to_complete_ids['champhai'])\n",
    "        data_modified[key].append(districts_to_complete_ids['khawzawl'])\n",
    "        data_modified[key].append(districts_to_complete_ids['serchhip'])\n",
    "        data_modified[districts_to_complete_ids['aizawl']].append(key)\n",
    "        data_modified[districts_to_complete_ids['champhai']].append(key)\n",
    "        data_modified[districts_to_complete_ids['khawzawl']].append(key)\n",
    "        data_modified[districts_to_complete_ids['serchhip']].append(key)\n",
    "    elif key.split('/')[0]== 'champhai':\n",
    "        for key2 in data_modified[key]:\n",
    "            if key2.split('/')[0] == 'aizwal':\n",
    "                data_modified[key].remove(key2)\n",
    "    elif key.split('/')[0]== 'yanam':\n",
    "        data_modified[key].append(districts_to_complete_ids['east godavari'])\n",
    "        data_modified[districts_to_complete_ids['east godavari']].append(key)\n",
    "    elif key.split('/')[0]== 'tenkasi':\n",
    "        data_modified[key].append(districts_to_complete_ids['tirunelveli'])\n",
    "        data_modified[key].append(districts_to_complete_ids['virudhunagar'])\n",
    "        data_modified[key].append(districts_to_complete_ids['kollam'])\n",
    "        data_modified[key].append(districts_to_complete_ids['thiruvananthapuram'])\n",
    "        data_modified[key].append(districts_to_complete_ids['thoothukkudi'])\n",
    "        data_modified[districts_to_complete_ids['tirunelveli']].append(key)\n",
    "        data_modified[districts_to_complete_ids['virudhunagar']].append(key)\n",
    "        data_modified[districts_to_complete_ids['kollam']].append(key)\n",
    "        data_modified[districts_to_complete_ids['thiruvananthapuram']].append(key)\n",
    "        data_modified[districts_to_complete_ids['thoothukkudi']].append(key)   \n",
    "    elif key.split('/')[0]== 'tirunelveli':\n",
    "        for key2 in data_modified[key]:\n",
    "            if key2.split('/')[0] == 'idukki' or key2.split('/')[0] == 'virudhunagar' or key2.split('/')[0] == 'kollam' or key2.split('/')[0] == 'thiruvananthapuram':\n",
    "                data_modified[key].remove(key2)\n",
    "                data_modified[key2].remove(key)\n",
    "    elif key.split('/')[0]== 'mumbai':\n",
    "        data_modified[key].append(districts_to_complete_ids['thane'])\n",
    "        data_modified[districts_to_complete_ids['thane']].append(key)\n",
    "    elif key.split('/')[0]== 'delhi':\n",
    "        data_modified[key].append(districts_to_complete_ids['ghaziabad'])\n",
    "        data_modified[key].append(districts_to_complete_ids['gautam buddha nagar'])\n",
    "        data_modified[key].append(districts_to_complete_ids['gurugram'])\n",
    "        data_modified[key].append(districts_to_complete_ids['sonipat'])\n",
    "        data_modified[key].append(districts_to_complete_ids['baghpat'])\n",
    "        data_modified[key].append(districts_to_complete_ids['jhajjar'])\n",
    "        data_modified[key].append(districts_to_complete_ids['faridabad'])\n",
    "        data_modified[districts_to_complete_ids['ghaziabad']].append(key)\n",
    "        data_modified[districts_to_complete_ids['gautam buddha nagar']].append(key)\n",
    "        data_modified[districts_to_complete_ids['gurugram']].append(key)\n",
    "        data_modified[districts_to_complete_ids['sonipat']].append(key)\n",
    "        data_modified[districts_to_complete_ids['baghpat']].append(key)\n",
    "        data_modified[districts_to_complete_ids['jhajjar']].append(key)\n",
    "        data_modified[districts_to_complete_ids['faridabad']].append(key)   \n",
    "    data_modified[key].sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"neighbor-districts-modified.json\", \"w\") as outfile:  \n",
    "    json.dump(data_modified, outfile, indent = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting districts alphabetically\n",
    "districts_from_json = []\n",
    "for i in data_modified:\n",
    "    districts_from_json.append(i)\n",
    "districts_from_json = np.array(districts_from_json)\n",
    "districts_from_json.sort()\n",
    "\n",
    "# ids for districts\n",
    "ids = np.arange(101,101+len(districts_from_json))\n",
    "\n",
    "# Dictionary for storing ids of districts\n",
    "Dict = {} \n",
    "for i in range(len(ids)):\n",
    "    Dict[districts_from_json[i]]=ids[i]\n",
    "\n",
    "data_ids = {}\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    data_ids[districts_from_json[i].split('/')[0] + '/' + str(ids[i])] = data_modified[districts_from_json[i]].copy()\n",
    "\n",
    "for key in data_ids.keys():\n",
    "    for j in range(len(data_ids[key])):\n",
    "        curr_id = Dict[data_ids[key][j]]\n",
    "        data_ids[key][j] = data_ids[key][j].split('/')[0] + '/' + str(curr_id)\n",
    "# for key in data_modified.keys():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"neighbor-districts-modified.json\", \"w\") as outfile:  \n",
    "    json.dump(data_ids, outfile, indent = 4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
